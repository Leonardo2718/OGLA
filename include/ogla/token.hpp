/*
Project: OGLA
File: token.hpp
Author: Leonardo Banderali
Created: July 7, 2015
Last Modified: August 30, 2015

Description:
    A `Token` is a unit of analyzed text and is identified using a `Rule`.  These form the basic building blocks of the
    OGLA lexcial analyzer.  Tokens should be immutable as they represent the result of a computation (lexical analysis).

Copyright (C) 2015 Leonardo Banderali
Distributed under the Boost Software License, Version 1.0.
(See accompanying file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)

*/

#ifndef OGLA_TOKEN_HPP
#define OGLA_TOKEN_HPP

//include standard c++ libraries
#include <string>
#include <vector>
#include <regex>

namespace ogla {

//~forward declarations and function prototypes~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

template <typename NextStateType> class BasicRule;  // type for describing a rule used to identify a token
class Token;                                        // type representing a token in analyzed text
using TokenList = std::vector<Token>;
struct TokenRulePair;



//~class templates~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

/*
A class template for describing a rule used to find a token (a tokenization rule).  A rule essentially containes the
information needed by a lexer to find a token.  It also containes some information (a hint) as to what the lexer
*should* do if it finds a token using this rule.  Semantically, this information is represented as a state.  This makes
the most sence when thinking about the lexer as a finite-state-machine (FSM).

Rules have three basic properties:
1. a name (which should be the same as the name of the tokens the rule finds)
2. the regular expression used to search text
3. a definition of what the state of a lexer should be after generating/finding a token using the rule

Each rule should only be used to search for a single category of token.  For example, "keyword" can be a category.
*/
template <typename NextStateType>
class BasicRule {
    public:
        BasicRule(NextStateType _nextState) : nextState{_nextState} {}
        BasicRule(const std::string& _name, const std::string& _regex, NextStateType _nState)
            : ruleName{_name}, rgx{_regex}, nState{_nState} {}

        std::string name() const;
        /*  returns the name of the rule (which should match the name of the token it defines) */

        std::regex regex() const;
        /*  returns the regular expression used to find the token associated with this rule */

        NextStateType nextState() const;
        /*  returns the state the lexer should have after finding a token from this rule */

    private:
        std::string ruleName;
        std::regex rgx;         // holds the regular expression (regex) used to indentify the token
        NextStateType nState;   // points to (but does not own) the next rules to be used for tokenization
};

/*
returns the name of the rule (which should match the name of the token it defines)
*/
template <typename NextStateType>
std::string BasicRule<NextStateType>::name() const {
    return ruleName;
}

/*
returns the regular expression used to find the token associated with this rule
*/
template <typename NextStateType>
std::regex BasicRule<NextStateType>::regex() const {
    return rgx;
}

/*
returns the state the lexer should have after finding a token from this rule
*/
template <typename NextStateType>
NextStateType BasicRule<NextStateType>::nextState() const {
    return nState;
}



//~classes~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

/*
As the name suggests, `Token` is a class that represents a token.  Tokens are generated by a lexer using rules.
For the sake of generality, an instance of this class only containes basic information about a token, including:
its name (or category), its corresponding lexeme, and its position in the text (which may be specified optionally).
Any other information needed must be extracted by the user from the lexeme and other information already provided.
This essentailly offloads the work of learning the value of a token to an other tool such as a parser or semantic
analyzer.
*/
class Token {
    public:
        Token() = default;
        Token(const std::string& _ruleName, const std::smatch& _match, int _pos = -1)
            :ruleName{_ruleName}, match{_match}, pos{_pos} {}

        bool empty() const;
        /*  returns true if the token is the result of an empty match (search result is empty) */

        std::string name() const;
        /*  returns the name of the token (should match name of the rule used to find it) */

        int position() const;
        /*  returns the specifed position of the token within the text searched (-1 is "no/don't care position") */

        int length() const;
        /*  returns the length of the lexeme (will be deprecated) */

        std::string lexeme() const;
        /*  returns the lexeme of this token */

        bool operator==(const Token& other) const;

        bool operator!=(const Token& other) const;

    private:
        std::string ruleName;
        std::smatch match;  // the matched lexeme associated with the token
        int pos = -1;       // the assigned position of the token in the text (-1 is "no/don't care position")
};

}   // `ogla` namepsace

#endif//OGLA_TOKEN_HPP
